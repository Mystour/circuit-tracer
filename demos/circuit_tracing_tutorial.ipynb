{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mystour/circuit-tracer/blob/main/demos/circuit_tracing_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQfpPNnLwnEi"
      },
      "source": [
        "# Circuit Tracing Tutorial\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/safety-research/circuit-tracer/blob/main/demos/circuit_tracing_tutorial.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "This notebook serves as a tutorial for the circuit tracing library. The library enables users to explain model behavior by generating Attribution Graphs (introduced in [Circuit Tracing](https://transformer-circuits.pub/2025/attribution-graphs/methods.html)), and validate these explanations with experiments.\n",
        "\n",
        "If you'd like to generate your own graphs, you can do so on [Neuronpedia](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-dallas-austin&pruningThreshold=0.6&pinnedIds=27_22605_10%2C20_15589_10%2CE_26865_9%2C21_5943_10%2C23_12237_10%2C20_15589_9%2C16_25_9%2C14_2268_9%2C18_8959_10%2C4_13154_9%2C7_6861_9%2C19_1445_10%2CE_2329_7%2CE_6037_4%2C0_13727_7%2C6_4012_7%2C17_7178_10%2C15_4494_4%2C6_4662_4%2C4_7671_4%2C3_13984_4%2C1_1000_4%2C19_7477_9%2C18_6101_10%2C16_4298_10%2C7_691_10&supernodes=%5B%5B%22capital%22%2C%2215_4494_4%22%2C%226_4662_4%22%2C%224_7671_4%22%2C%223_13984_4%22%2C%221_1000_4%22%5D%2C%5B%22state%22%2C%226_4012_7%22%2C%220_13727_7%22%5D%2C%5B%22Texas%22%2C%2220_15589_9%22%2C%2219_7477_9%22%2C%2216_25_9%22%2C%224_13154_9%22%2C%2214_2268_9%22%2C%227_6861_9%22%5D%2C%5B%22preposition+followed+by+place+name%22%2C%2219_1445_10%22%2C%2218_6101_10%22%5D%2C%5B%22capital+cities+%2F+say+a+capital+city%22%2C%2221_5943_10%22%2C%2217_7178_10%22%2C%227_691_10%22%2C%2216_4298_10%22%5D%5D&densityThreshold=0.99&clerps=%5B%5B%2223_2312237_10%22%2C%22Cities+and+states+names+%28say+Austin%29%22%5D%2C%5B%2218_1808959_10%22%2C%22state+%2F+regional+government%22%5D%5D). You can also do so directly on Colab using this [starter notebook](https://github.com/safety-research/circuit-tracer/blob/main/demos/attribute_demo.ipynb).\n",
        "\n",
        "In this demo, we'll dive  into a couple of attribution graphs involving Gemma 2 (2B), based on the Multi-Step Reasoning and Multilingual Circuits examples [in the original paper](https://transformer-circuits.pub/2025/attribution-graphs/biology.html). We'll view the graphs, annotated with labeled supernodes, and then perform interventions to verify that the supernodes' labels are indeed correct, and that interventions have the effect we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616,
          "referenced_widgets": [
            "cbc548ab8d6244d0ac2aa3efa1a5c7ba",
            "1bdd7d94c97a43059b002c08b14c2d48",
            "6f7a27be5e4b49008ed7264b84a3d7c9",
            "4b25a544382e417697280244428f6cb8",
            "ed422e65078e4e14a84796b6b68fe186",
            "1cd509497bac48d4b902f2cb40f88d86",
            "7b900d11e03b46ca9eb0a629880a3d33",
            "bb4c9b6ebc004f33a42e3951e18aa776",
            "7032326d764c4c839df6d6cb29350ffd",
            "c8ad32ab93ad40a0a1688c71e1310493",
            "d2bbde3f880147b4ae44fb01bb9accf6",
            "91307a3ffe1548cd851c74c72a5a4361",
            "a22b25b7cd85443d9bb910a8007edab9",
            "cd7a80e9316141828f54c214c30b7f22",
            "f6a7580a95614e84a920dff0cd5880a5",
            "6eae30c213244d12965934f553ae9216",
            "636e1999c22f4c57be7b0ec6a92dbaf6"
          ]
        },
        "id": "szUkZGa0wnEj",
        "outputId": "d0e694c8-69e9-422d-ea92-9e7f4b25554b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/repository\n",
            "Cloning into 'circuit-tracer'...\n",
            "remote: Enumerating objects: 443, done.\u001b[K\n",
            "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 443 (delta 191), reused 120 (delta 89), pack-reused 147 (from 2)\u001b[K\n",
            "Receiving objects: 100% (443/443), 2.32 MiB | 9.83 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "downloading uv 0.9.18 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /usr/local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/usr/local/lib/python3.12/dist-packages/~orch-2.3.0.dist-info\u001b[39m`\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mIgnoring dangling temporary directory: `\u001b[36m/usr/local/lib/python3.12/dist-packages/~vidia_cudnn_cu12-8.9.2.26.dist-info\u001b[39m`\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m111 packages\u001b[0m \u001b[2min 512ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 3.29s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 121ms\u001b[0m\u001b[0m\n",
            " \u001b[33m~\u001b[39m \u001b[1mcircuit-tracer\u001b[0m\u001b[2m==0.1.0 (from file:///content/repository/circuit-tracer)\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.57.3\u001b[0m\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbc548ab8d6244d0ac2aa3efa1a5c7ba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Colab Setup Environment (修复版)\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    # 先清理已存在的目录\n",
        "    !rm -rf repository/\n",
        "\n",
        "    # 创建目录并克隆仓库\n",
        "    !mkdir -p repository\n",
        "    %cd repository\n",
        "    !git clone https://github.com/safety-research/circuit-tracer\n",
        "\n",
        "    # 安装uv工具\n",
        "    !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
        "\n",
        "    # 安装circuit-tracer包\n",
        "    !uv pip install -e circuit-tracer/\n",
        "\n",
        "    # 返回上级目录\n",
        "    %cd ..\n",
        "\n",
        "    import sys\n",
        "    from huggingface_hub import notebook_login\n",
        "    sys.path.append('repository/circuit-tracer')\n",
        "    sys.path.append('repository/circuit-tracer/demos')\n",
        "    notebook_login(new_session=False)\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 设置 Hugging Face Token\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# 获取 HF_TOKEN（会弹出对话框让你输入）\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "except Exception as e:\n",
        "    print(\"请在 Colab Secrets 中设置 HF_TOKEN:\")\n",
        "    print(\"1. 点击左侧边栏的 '钥匙' 图标\")\n",
        "    print(\"2. 点击 '+ Add secret'\")\n",
        "    print(\"3. Name: HF_TOKEN\")\n",
        "    print(\"4. Value: 你的 Hugging Face token\")\n",
        "    print(\"5. 点击 'Save'\")\n",
        "    raise e\n",
        "\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "print(\"✅ HF_TOKEN 已设置！\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "fPXlGyEk5uuV",
        "outputId": "fdf2258c-6739-479f-b056-70779a540a6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "请在 Colab Secrets 中设置 HF_TOKEN:\n",
            "1. 点击左侧边栏的 '钥匙' 图标\n",
            "2. 点击 '+ Add secret'\n",
            "3. Name: HF_TOKEN\n",
            "4. Value: 你的 Hugging Face token\n",
            "5. 点击 'Save'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SecretNotFoundError",
          "evalue": "Secret HF_TOKEN does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1269303927.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4. Value: 你的 Hugging Face token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5. 点击 'Save'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HF_TOKEN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1269303927.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 获取 HF_TOKEN（会弹出对话框让你输入）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mhf_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HF_TOKEN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"请在 Colab Secrets 中设置 HF_TOKEN:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret HF_TOKEN does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715,
          "referenced_widgets": [
            "82cb43ff71214661b3169c11e59873c1",
            "c0f4a35354694d7ca6cbc9ea6ba5a81d",
            "65e0c491ea9d46f9aa94815347ab3c8b",
            "f057b54a37da4248a0cecf3f84478a23",
            "214248cba974429cbcb182cc7835040f",
            "ce812c45f7474e4e8d083e2cc0f1c16b",
            "7ade0969029a44ea9fd1b737c170e3fe",
            "b20e96bce00e4a8281a5319db5b4ee5b",
            "1efab0384559440a9c60d2e09ee10ea3",
            "5e212e5f2e76473d9370391b432ed645",
            "7b33b45ccaf84bd8af9403b9659913c7"
          ]
        },
        "id": "UN8vCL15wnEj",
        "outputId": "972f173e-1ba9-4dbe-882d-299d1e7af759"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 26 files:   0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82cb43ff71214661b3169c11e59873c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n401 Client Error. (Request ID: Root=1-69526862-07e65dd2656e32392b6b32be;1bc68858-bfc4-4b8e-a197-7f303ab19e07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2-2b/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGatedRepoError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-69526862-07e65dd2656e32392b6b32be;1bc68858-bfc4-4b8e-a197-7f303ab19e07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4039134955.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcircuit_tracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_url_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_url_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplacementModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/gemma-2-2b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gemma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/repository/circuit-tracer/circuit_tracer/replacement_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name, transcoder_set, device, dtype, lazy_encoder, lazy_decoder, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         )\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         return cls.from_pretrained_and_transcoders(\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtranscoders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/repository/circuit-tracer/circuit_tracer/replacement_model.py\u001b[0m in \u001b[0;36mfrom_pretrained_and_transcoders\u001b[0;34m(cls, model_name, transcoders, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mReplacementModel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mReplacementModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         model = super().from_pretrained(\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfold_ln\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformer_lens/HookedTransformer.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# match the HookedTransformer parameter names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         state_dict = loading.get_pretrained_state_dict(\n\u001b[0m\u001b[1;32m   1371\u001b[0m             \u001b[0mofficial_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfrom_pretrained_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformer_lens/loading_from_pretrained.py\u001b[0m in \u001b[0;36mget_pretrained_state_dict\u001b[0;34m(official_model_name, cfg, hf_model, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 )\n\u001b[1;32m   1938\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                 hf_model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m   1940\u001b[0m                     \u001b[0mofficial_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_raise_exceptions_for_gated_repo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;34m\"You are trying to access a gated repo.\\nMake sure to have access to it at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;34mf\"https://huggingface.co/{path_or_repo_id}.\\n{str(e)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n401 Client Error. (Request ID: Root=1-69526862-07e65dd2656e32392b6b32be;1bc68858-bfc4-4b8e-a197-7f303ab19e07)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in."
          ]
        }
      ],
      "source": [
        "from collections import namedtuple\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch\n",
        "\n",
        "from circuit_tracer import ReplacementModel\n",
        "from circuit_tracer.utils.decode_url_features import decode_url_features\n",
        "\n",
        "model = ReplacementModel.from_pretrained(\"google/gemma-2-2b\", 'gemma', dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MErMknCyw8UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL3eU9bzwnEk"
      },
      "source": [
        "# Two-hop reasoning\n",
        "We'll start with the example [`Fact: The capital of the state containing Dallas is` → `Austin`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-dallas-austin&pruningThreshold=0.6&pinnedIds=27_22605_10%2C20_15589_10%2CE_26865_9%2C21_5943_10%2C23_12237_10%2C20_15589_9%2C16_25_9%2C14_2268_9%2C18_8959_10%2C4_13154_9%2C7_6861_9%2C19_1445_10%2CE_2329_7%2CE_6037_4%2C0_13727_7%2C6_4012_7%2C17_7178_10%2C15_4494_4%2C6_4662_4%2C4_7671_4%2C3_13984_4%2C1_1000_4%2C19_7477_9%2C18_6101_10%2C16_4298_10%2C7_691_10&supernodes=%5B%5B%22capital%22%2C%2215_4494_4%22%2C%226_4662_4%22%2C%224_7671_4%22%2C%223_13984_4%22%2C%221_1000_4%22%5D%2C%5B%22state%22%2C%226_4012_7%22%2C%220_13727_7%22%5D%2C%5B%22Texas%22%2C%2220_15589_9%22%2C%2219_7477_9%22%2C%2216_25_9%22%2C%224_13154_9%22%2C%2214_2268_9%22%2C%227_6861_9%22%5D%2C%5B%22preposition+followed+by+place+name%22%2C%2219_1445_10%22%2C%2218_6101_10%22%5D%2C%5B%22capital+cities+%2F+say+a+capital+city%22%2C%2221_5943_10%22%2C%2217_7178_10%22%2C%227_691_10%22%2C%2216_4298_10%22%5D%5D&densityThreshold=0.99&clerps=%5B%5B%2223_2312237_10%22%2C%22Cities+and+states+names+%28say+Austin%29%22%5D%2C%5B%2218_1808959_10%22%2C%22state+%2F+regional+government%22%5D%5D), which requires two hop-reasoning. The model must first reason that the state containing Dallas is Texas; then, it must respond with the capital of Texas, Austin.\n",
        "\n",
        "[The original paper](https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-tracing) showed that Haiku solves the problem using the following circuit, computing the intermediate step of the state containing Dallas: Texas.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/safety-research/circuit-tracer/main/demos/img/dallas-austin-haiku.png\" width=\"300\" />\n",
        "\n",
        "Performing attribution on Gemma 2 (2B) shows that it uses [this circuit](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-dallas-austin&pruningThreshold=0.6&pinnedIds=27_22605_10%2C20_15589_10%2CE_26865_9%2C21_5943_10%2C23_12237_10%2C20_15589_9%2C16_25_9%2C14_2268_9%2C18_8959_10%2C4_13154_9%2C7_6861_9%2C19_1445_10%2CE_2329_7%2CE_6037_4%2C0_13727_7%2C6_4012_7%2C17_7178_10%2C15_4494_4%2C6_4662_4%2C4_7671_4%2C3_13984_4%2C1_1000_4%2C19_7477_9%2C18_6101_10%2C16_4298_10%2C7_691_10&supernodes=%5B%5B%22capital%22%2C%2215_4494_4%22%2C%226_4662_4%22%2C%224_7671_4%22%2C%223_13984_4%22%2C%221_1000_4%22%5D%2C%5B%22state%22%2C%226_4012_7%22%2C%220_13727_7%22%5D%2C%5B%22Texas%22%2C%2220_15589_9%22%2C%2219_7477_9%22%2C%2216_25_9%22%2C%224_13154_9%22%2C%2214_2268_9%22%2C%227_6861_9%22%5D%2C%5B%22preposition+followed+by+place+name%22%2C%2219_1445_10%22%2C%2218_6101_10%22%5D%2C%5B%22capital+cities+%2F+say+a+capital+city%22%2C%2221_5943_10%22%2C%2217_7178_10%22%2C%227_691_10%22%2C%2216_4298_10%22%5D%5D&densityThreshold=0.99&clerps=%5B%5B%2223_2312237_10%22%2C%22Cities+and+states+names+%28say+Austin%29%22%5D%2C%5B%2218_1808959_10%22%2C%22state+%2F+regional+government%22%5D%5D) to successfully complete the prompt:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/safety-research/circuit-tracer/main/demos/img/gemma/dallas-austin-new.png\" width=\"600\" />\n",
        "\n",
        "The circuit is similar: it has a node corresponding to Texas, and shows both a direct path from Dallas to Austin as well as an indirect path going through Texas. The Attribution Graph suggests a hypothesis about model behavior, based on using transcoders to approximate the behavior of MLPs. We can verify that our understanding of model behavior is correct by performing interventions directly on the underlying model.\n",
        "\n",
        "We'll perform interventions on each of the supernodes shown. So, we will first get the supernodes from this graph. We have a convenience function that will map a circuit URL (and the supernodes stored therein), to a list of Feature objects; each Feature is a tuple of `(layer, position, feature_index)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bn6EEyEFwnEk"
      },
      "outputs": [],
      "source": [
        "dallas_austin_url=\"https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-dallas-austin&clerps=%5B%5D&pruningThreshold=0.53&pinnedIds=27_22605_10%2C20_15589_10%2CE_26865_9%2C21_5943_10%2C23_12237_10%2C20_15589_9%2C16_25_9%2C14_2268_9%2C18_8959_10%2C4_13154_9%2C7_6861_9%2C19_1445_10%2CE_2329_7%2CE_6037_4%2C0_13727_7%2C6_4012_7%2C17_7178_10%2C15_4494_4%2C6_4662_4%2C4_7671_4%2C3_13984_4%2C1_1000_4%2C19_7477_9%2C18_6101_10%2C16_4298_10%2C7_691_10&supernodes=%5B%5B%22capital%22%2C%2215_4494_4%22%2C%226_4662_4%22%2C%224_7671_4%22%2C%223_13984_4%22%2C%221_1000_4%22%5D%2C%5B%22state%22%2C%226_4012_7%22%2C%220_13727_7%22%5D%2C%5B%22Texas%22%2C%2220_15589_9%22%2C%2219_7477_9%22%2C%2216_25_9%22%2C%224_13154_9%22%2C%2214_2268_9%22%2C%227_6861_9%22%5D%2C%5B%22preposition+followed+by+place+name%22%2C%2219_1445_10%22%2C%2218_6101_10%22%5D%2C%5B%22capital+cities+%2F+say+a+capital+city%22%2C%2221_5943_10%22%2C%2217_7178_10%22%2C%227_691_10%22%2C%2216_4298_10%22%5D%5D\"\n",
        "supernode_features, _ = decode_url_features(dallas_austin_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQj1-VL7wnEk"
      },
      "source": [
        "We'll then create a representation of the circuit being used to solve this task. This means defining some Supernode objects, which will store a list of underlying features, as well as their children supernodes that they have a causal effect on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOr3bl5nwnEl"
      },
      "outputs": [],
      "source": [
        "from graph_visualization import create_graph_visualization, Supernode, InterventionGraph, Feature\n",
        "\n",
        "# Supernodes that upweight certain outputs. Note that e.g. the Say Austin node is not the only node promoting Austin, but that is its primary role\n",
        "say_austin_node = Supernode(name='Say Austin', features=[Feature(layer=23, pos=10, feature_idx=12237)])\n",
        "say_capital_node = Supernode(name='Say a capital', features=supernode_features['capital cities / say a capital city'], children=[say_austin_node])\n",
        "\n",
        "# Intermediate nodes\n",
        "texas_node = Supernode(name='Texas', features=supernode_features['Texas'], children=[say_austin_node])\n",
        "state_node = Supernode(name='state', features=supernode_features['state'], children=[say_capital_node, texas_node])\n",
        "capital_node = Supernode(name='capital', features=supernode_features['capital'], children=[say_capital_node])\n",
        "\n",
        "# Embedding nodes\n",
        "dallas_node = Supernode(name='Emb: Dallas', features=None, children=[texas_node])\n",
        "state_emb_node = Supernode(name='Emb: state', features=None, children=[state_node])\n",
        "capital_emb_node = Supernode(name='Emb: capital', features=None, children=[capital_node])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXRmTUzwwnEl"
      },
      "source": [
        "We then initialize an InterventionGraph, which stores all of our Supernodes, and keeps track of their state. We'll also get the model's logits and activations on this prompt. We then set each node's default activation (its activation on the original prompt, without interventions), and set its activation fraction. The activation fraction is the node's current activation / its default activation. Since the current and default activations are the same, each node is at 100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAmWm5tMwnEl"
      },
      "outputs": [],
      "source": [
        "prompt = \"Fact: the capital of the state containing Dallas is\"\n",
        "ordered_nodes = [[capital_emb_node, state_emb_node],[capital_node, state_node, dallas_node],[say_capital_node, texas_node], [say_austin_node]]\n",
        "dallas_austin_graph = InterventionGraph(ordered_nodes=ordered_nodes, prompt=prompt)\n",
        "\n",
        "logits, dallas_activations = model.get_activations(prompt)\n",
        "\n",
        "# initialize each node, adding it to the intervention graph and recording its default activation\n",
        "for node in [capital_node, state_node, dallas_node, say_capital_node, texas_node, say_austin_node]:\n",
        "    dallas_austin_graph.initialize_node(node, dallas_activations)\n",
        "\n",
        "# set each node's current activation to a percent of its default activation (here 100%)\n",
        "dallas_austin_graph.set_node_activation_fractions(dallas_activations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyARGkWDwnEl"
      },
      "source": [
        "We'll record the top-5 logits as well, and then visualize our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozcIqqs2wnEl"
      },
      "outputs": [],
      "source": [
        "def get_top_outputs(logits: torch.Tensor, k: int = 5):\n",
        "    top_probs, top_token_ids = logits.squeeze(0)[-1].softmax(-1).topk(k)\n",
        "    top_tokens = [model.tokenizer.decode(token_id) for token_id in top_token_ids]\n",
        "    top_outputs = list(zip(top_tokens, top_probs.tolist()))\n",
        "    return top_outputs\n",
        "\n",
        "top_outputs = get_top_outputs(logits)\n",
        "\n",
        "create_graph_visualization(dallas_austin_graph, top_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHm1o9zLwnEl"
      },
      "source": [
        "The displayed circuit is consistent with the supernodes we created when visualizing the full graph. We'll now verify that each supernode plays the role we hypothesized using interventions. Each intervention will set a node's value to some multiple of its original value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAhTT-ckwnEm"
      },
      "outputs": [],
      "source": [
        "# An Intervention says \"set the activation of supernode to intervention_value * its activation in the given activations tensor\"\n",
        "Intervention = namedtuple('Intervention', ['supernode', 'scaling_factor'])\n",
        "def supernode_intervention(intervention_graph: InterventionGraph, interventions: List[Intervention], replacements: Dict[str, Supernode] = None):\n",
        "    \"\"\"Performs interventions on a set of supernodes, records the outputs, and draws the corresponding graph\n",
        "\n",
        "    Args:\n",
        "        interventions (List[Intervention]): List of interventions to perform\n",
        "        replacements (Dict[str, Supernode], optional): Replacement supernodes to add, if we're adding supernodes\n",
        "            from another prompt. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        HTML: An IPython.display.HTML object showing the graph corresponding to these interventions\n",
        "    \"\"\"\n",
        "    intervention_values = [(*feature, scaling_factor * default_act) for intervened_supernode, scaling_factor in interventions\n",
        "                           for feature, default_act in zip(intervened_supernode.features, intervened_supernode.default_activations)]\n",
        "    new_logits, new_activations = model.feature_intervention(intervention_graph.prompt, intervention_values)\n",
        "    intervention_graph.set_node_activation_fractions(new_activations)\n",
        "    top_outputs = get_top_outputs(new_logits)\n",
        "\n",
        "    for intervened_supernode, scaling_factor in interventions:\n",
        "        intervened_supernode.activation = None\n",
        "        intervened_supernode.intervention = f'{scaling_factor}x'\n",
        "\n",
        "    if replacements is not None:\n",
        "        for target, replacement in replacements.items():\n",
        "            intervention_graph.nodes[target].replacement_node = replacement\n",
        "\n",
        "    return create_graph_visualization(intervention_graph, top_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8X6YPk3wnEm"
      },
      "source": [
        "In the original paper, turning off the \"Say a capital\" feature caused the \"Say Austin\" supernode to shut off, and the model's top logit to change to Texas. What happens if we do the same?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPQULjc1wnEm"
      },
      "outputs": [],
      "source": [
        "supernode_intervention(dallas_austin_graph, [Intervention(say_capital_node, -2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvI_nL19wnEm"
      },
      "source": [
        "We observe precisely the same behavior! Strongly shutting off the \"Say a capital\" supernode turned off the \"Say Austin\" node, and changed the top logit to Texas.\n",
        "\n",
        "What if we turn off the \"capital\" supernode?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzBWamtkwnEm"
      },
      "outputs": [],
      "source": [
        "supernode_intervention(dallas_austin_graph, [Intervention(capital_node, -2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M35Eqmr2wnEm"
      },
      "source": [
        "This yields similar behavior to before. We turn off the \"Say a capital\" supernode, though not as strongly in as in the prior intervention. This also partially turns off the \"Say Austin\" node.\n",
        "\n",
        "What if we turn off the Texas supernode?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neqdP0LownEm"
      },
      "outputs": [],
      "source": [
        "supernode_intervention(dallas_austin_graph, [Intervention(texas_node, -2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7drP6vawnEm"
      },
      "source": [
        "Turning the Texas supernode off also disabled the \"Say Austin\" node, yielding the capitals of other states.\n",
        "\n",
        "What if we turn off the \"state\" supernode?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsliYJ2OwnEm"
      },
      "outputs": [],
      "source": [
        "supernode_intervention(dallas_austin_graph, [Intervention(state_node, -2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u4uZWBvwnEm"
      },
      "source": [
        "Turning off the state supernode was largely ineffective: it caused little change to any of the other supernode activations, and little change to the model logits.\n",
        "\n",
        "We’ve validated the behavior of nodes by ablating them. Could we inject entirely different nodes and validate that they have the expected effect? Take the circuit from the prompt [`Fact: The capital of the state containing Oakland is` → `Sacramento`]((https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-oakland-sacramento&pruningThreshold=0.5&pinnedIds=27_43939_10%2CE_49024_9%2C21_5943_10%2C19_9209_10%2C18_8959_10%2C14_12562_9%2C7_14530_9%2C8_14641_9%2C4_8625_9%2C19_9209_9%2C17_7178_10%2CE_6037_4%2C15_4494_4%2CE_2329_7%2C16_4298_10%2C7_691_10%2C6_4662_4%2C4_7671_4%2C2_8734_4%2C0_1961_4%2C6_13909_9%2C22_4367_10%2C21_2464_10&supernodes=%5B%5B%22capital%22%2C%226_4662_4%22%2C%2215_4494_4%22%2C%224_7671_4%22%2C%222_8734_4%22%2C%220_1961_4%22%5D%2C%5B%22capital%22%2C%2221_5943_10%22%2C%2216_4298_10%22%2C%2217_7178_10%22%2C%227_691_10%22%5D%2C%5B%22California%22%2C%2222_4367_10%22%2C%2221_2464_10%22%5D%2C%5B%22California%22%2C%226_13909_9%22%2C%228_14641_9%22%2C%2214_12562_9%22%5D%2C%5B%22Bay+Area+%28say+California%29%22%2C%2219_9209_9%22%2C%227_14530_9%22%2C%224_8625_9%22%5D%5D&clickedId=27_43939_10&densityThreshold=0.99&clerps=%5B%5B%2219_1909209_9%22%2C%22Bay+area%22%5D%2C%5B%2219_1909209_10%22%2C%22Bay+Area%22%5D%5D)). We'll add two supernodes from this graph—\"California\" and \"Say Sacramento\" to our InterventionGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96qc_v2uwnEm"
      },
      "outputs": [],
      "source": [
        "oakland_prompt = \"Fact: the capital of the state containing Oakland is\"\n",
        "_, oakland_activations = model.get_activations(oakland_prompt)\n",
        "\n",
        "oakland_url = \"https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-oakland-sacramento&clerps=%5B%5D&pruningThreshold=0.5&pinnedIds=27_43939_10%2CE_49024_9%2C21_5943_10%2C19_9209_10%2C18_8959_10%2C14_12562_9%2C7_14530_9%2C8_14641_9%2C4_8625_9%2C19_9209_9%2C17_7178_10%2CE_6037_4%2C15_4494_4%2CE_2329_7%2C16_4298_10%2C7_691_10%2C6_4662_4%2C4_7671_4%2C2_8734_4%2C0_1961_4%2C6_13909_9%2C22_4367_10%2C21_2464_10&supernodes=%5B%5B%22capital%22%2C%226_4662_4%22%2C%2215_4494_4%22%2C%224_7671_4%22%2C%222_8734_4%22%2C%220_1961_4%22%5D%2C%5B%22capital%22%2C%2221_5943_10%22%2C%2216_4298_10%22%2C%2217_7178_10%22%2C%227_691_10%22%5D%2C%5B%22California%22%2C%2222_4367_10%22%2C%2221_2464_10%22%5D%2C%5B%22Bay+Area+%28say+California%29%22%2C%227_14530_9%22%2C%224_8625_9%22%5D%2C%5B%22California%22%2C%226_13909_9%22%2C%228_14641_9%22%2C%2214_12562_9%22%5D%5D&clickedId=27_43939_10\"\n",
        "oakland_supernodes, _ = decode_url_features(oakland_url)\n",
        "\n",
        "say_sacramento_node = Supernode('Say Sacramento', features=[Feature(layer=19, pos=10, feature_idx=9209)])\n",
        "california_node = Supernode('California', features=oakland_supernodes['California'] + oakland_supernodes['California (2)'],\n",
        "                       children=[say_sacramento_node])\n",
        "\n",
        "for node in [say_sacramento_node, california_node]:\n",
        "    dallas_austin_graph.initialize_node(node, oakland_activations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfWTE7S8wnEn"
      },
      "source": [
        "Then, we'll perform an intervention, turning off the Texas supernode, and turning on the California one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-SeSHZfwnEn"
      },
      "outputs": [],
      "source": [
        "oakland_interventions = [Intervention(texas_node, -2), Intervention(california_node, 2)]\n",
        "supernode_intervention(dallas_austin_graph, oakland_interventions, {texas_node.name: california_node, say_austin_node.name: say_sacramento_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAsaXcjdwnEn"
      },
      "source": [
        "Doing this caused the \"Say Austin\" node to shut off entirely, while the \"Say Sacramento\" node began to activate! Our model's top output is now Sacramento, as well.\n",
        "\n",
        "We can also do this replacing states with countries. Take the circuit for [`Fact: The capital of the country containing Shanghai is` → `Beijing`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-shanghai-beijing&clerps=%5B%5D&clickedId=15_4494_4&pruningThreshold=0.45&pinnedIds=27_33395_10%2CE_38628_9%2C21_5943_10%2C19_12274_10%2C19_12274_9%2C14_12274_9%2C18_6101_10%2C17_7178_10%2C6_6811_9%2C4_4257_9%2C4_11570_9%2CE_6037_4%2C0_8885_4%2C18_7639_10%2C19_2695_10%2C16_4298_10%2C15_4494_4%2C6_4662_4&supernodes=%5B%5B%22China%22%2C%2219_12274_9%22%2C%2214_12274_9%22%2C%226_6811_9%22%2C%224_11570_9%22%2C%224_4257_9%22%5D%2C%5B%22China%22%2C%2219_12274_10%22%2C%2218_7639_10%22%5D%2C%5B%22capital%22%2C%2216_4298_10%22%2C%2217_7178_10%22%2C%2218_6101_10%22%2C%2219_2695_10%22%2C%2221_5943_10%22%5D%2C%5B%22capital+cities+%28say+city%29%22%2C%226_4662_4%22%2C%2215_4494_4%22%2C%220_8885_4%22%5D%5D). We'll do precisely what we did before, disabling Texas and activating the China supernode. This time, there is no \"Say Beijing\" node, but the effect of this intervention should be visible in the logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-LwlPa9wnEn"
      },
      "outputs": [],
      "source": [
        "shanghai_prompt = \"Fact: the capital of the country containing Shanghai is\"\n",
        "_, shanghai_activations = model.get_activations(shanghai_prompt)\n",
        "\n",
        "shanghai_url = \"https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-shanghai-beijing&clerps=%5B%5D&clickedId=15_4494_4&pruningThreshold=0.45&pinnedIds=27_33395_10%2CE_38628_9%2C21_5943_10%2C19_12274_10%2C19_12274_9%2C14_12274_9%2C18_6101_10%2C17_7178_10%2C6_6811_9%2C4_4257_9%2C4_11570_9%2CE_6037_4%2C0_8885_4%2C18_7639_10%2C19_2695_10%2C16_4298_10%2C15_4494_4%2C6_4662_4&supernodes=%5B%5B%22China%22%2C%2219_12274_9%22%2C%2214_12274_9%22%2C%226_6811_9%22%2C%224_11570_9%22%2C%224_4257_9%22%5D%2C%5B%22China%22%2C%2219_12274_10%22%2C%2218_7639_10%22%5D%2C%5B%22capital%22%2C%2216_4298_10%22%2C%2217_7178_10%22%2C%2218_6101_10%22%2C%2219_2695_10%22%2C%2221_5943_10%22%5D%2C%5B%22capital+cities+%28say+city%29%22%2C%226_4662_4%22%2C%2215_4494_4%22%2C%220_8885_4%22%5D%5D\"\n",
        "shanghai_supernodes, _ = decode_url_features(shanghai_url)\n",
        "\n",
        "china_node = Supernode('China', features=shanghai_supernodes['China'] + shanghai_supernodes['China (2)'])#,\n",
        "\n",
        "for node in [china_node]:\n",
        "    dallas_austin_graph.initialize_node(node, shanghai_activations)\n",
        "\n",
        "china_interventions = [Intervention(texas_node, -2), Intervention(china_node, 2)]\n",
        "supernode_intervention(dallas_austin_graph, china_interventions, {texas_node.name: china_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHHgrGzwnEn"
      },
      "source": [
        "This works as well! Beijing is now the models' most likely output.\n",
        "\n",
        "Does this always work? Let's try with the circuit for [`Fact: the capital of the territory containing Vancouver is` → `Victoria`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-vancouver-victoria&clickedId=4_11742_9&pruningThreshold=0.45&pinnedIds=27_18221_10%2CE_32936_9%2C21_2236_10%2C19_15123_10%2C18_1025_10%2C14_12562_9%2C14_5600_9%2C6_11873_9%2C4_8439_9%2CE_6037_4%2CE_19412_7%2C4_11742_9%2C0_16137_7&supernodes=%5B%5B%22Canada%22%2C%2214_5600_9%22%2C%226_11873_9%22%2C%224_8439_9%22%5D%5D&densityThreshold=0.99&clerps=%5B%5B%2214_1412562_9%22%2C%22California%22%5D%2C%5B%224_411742_9%22%2C%22Pacific+northwest%22%5D%2C%5B%2221_2102236_10%22%2C%22Victoria%22%5D%2C%5B%2218_1801025_10%22%2C%22British+Columbia%22%5D%5D)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAv9c63fwnEn"
      },
      "outputs": [],
      "source": [
        "vancouver_prompt = \"Fact: the capital of the territory containing Vancouver is\"\n",
        "_, vancouver_activations = model.get_activations(vancouver_prompt)\n",
        "\n",
        "vancouver_url = \"https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-fact-vancouver-victoria&clerps=%5B%5D&clickedId=4_11742_9&pruningThreshold=0.45&pinnedIds=27_18221_10%2CE_32936_9%2C21_2236_10%2C19_15123_10%2C18_1025_10%2C14_12562_9%2C14_5600_9%2C6_11873_9%2C4_8439_9%2CE_6037_4%2CE_19412_7%2C4_11742_9%2C0_16137_7&supernodes=%5B%5B%22Canada%22%2C%2214_5600_9%22%2C%226_11873_9%22%2C%224_8439_9%22%5D%5D\"\n",
        "vancouver_supernodes, _ = decode_url_features(vancouver_url)\n",
        "\n",
        "say_victoria_node = Supernode('Say Victoria', features=[Feature(layer=21, pos=10, feature_idx=2236)])\n",
        "bc_node = Supernode('British Columbia', features=[Feature(layer=18, pos=10, feature_idx=1025)],\n",
        "                       children=[say_victoria_node])\n",
        "\n",
        "for node in [say_victoria_node, bc_node]:\n",
        "    dallas_austin_graph.initialize_node(node, vancouver_activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsU9mBmcwnEn"
      },
      "outputs": [],
      "source": [
        "bc_interventions = [Intervention(texas_node, -2), Intervention(bc_node, 2)]\n",
        "supernode_intervention(dallas_austin_graph, bc_interventions, {texas_node.name: bc_node, say_austin_node.name: say_victoria_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja4p91CWwnEn"
      },
      "source": [
        "In this case, the intervention was not very effective. The model's output looks like it did when just ablating Texas, which indicates that the addition of British Columbia did little. A motivated reader might want to try activating the British Columbia node more strongly - what happens?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e25DksePwnEn"
      },
      "source": [
        "## Multilingual Circuits\n",
        "\n",
        "In this section, we'll look at multilingual circuits, as studied [in the original paper](https://transformer-circuits.pub/2025/attribution-graphs/biology.html#dives-multilingual). Specifically, we'll look at three circuits, for the same sentence in 3 languages:\n",
        "- English: [`The opposite of \"small\" is \"` → `big`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-en&pruningThreshold=0.65&pinnedIds=27_13210_8%2CE_10498_5%2C23_8683_8%2C21_10062_8%2C17_12530_5%2C18_9402_8%2C6_4362_5%2C15_5617_5%2C15_5756_5%2C19_5058_8%2C14_11360_5%2CE_13388_2%2C15_7209_2%2C4_95_2%2C3_6576_2%2C27_7773_8%2C7_10545_5&supernodes=%5B%5B%22Output+%5C%22big%5C%22+or+%5C%22large%5C%22%22%2C%2227_7773_8%22%2C%2227_13210_8%22%5D%2C%5B%22say+big+%2F+huge+%2F+large%22%2C%2221_10062_8%22%2C%2223_8683_8%22%5D%2C%5B%22opposite%22%2C%224_95_2%22%2C%2215_7209_2%22%2C%223_6576_2%22%5D%2C%5B%22small%22%2C%2214_11360_5%22%2C%2217_12530_5%22%2C%2215_5617_5%22%5D%2C%5B%22large+%2F+size%22%2C%226_4362_5%22%2C%227_10545_5%22%2C%2215_5756_5%22%5D%5D&clickedId=6_4362_5&densityThreshold=0.99&clerps=%5B%5B%2219_1905058_8%22%2C%22comparatives%22%5D%5D)\n",
        "- French: [`Le contraire de \"petit\" est \"` → `grand`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-fr&pruningThreshold=0.65&pinnedIds=27_21996_8%2CE_64986_5%2C24_16045_8%2C19_5058_8%2C21_10062_8%2C23_2592_8%2C20_1454_8%2CE_63265_2%2C23_8683_8%2C23_8488_8%2C20_11434_8%2C19_5802_8%2CE_1455_7%2C15_5617_5%2C18_9402_8%2C6_4362_5%2C14_11360_5%2C3_2908_5%2C2_5452_5%2C3_6627_5%2C6_16184_2%2C4_95_2%2C22_10566_8%2C21_1144_8%2CE_2025_1%2CE_581_3&supernodes=%5B%5B%22opposite%22%2C%226_16184_2%22%2C%224_95_2%22%5D%2C%5B%22say+big+%2F+large%22%2C%2223_8683_8%22%2C%2223_8488_8%22%2C%2221_10062_8%22%5D%2C%5B%22comparatives%22%2C%2219_5058_8%22%2C%2224_16045_8%22%2C%2220_11434_8%22%5D%2C%5B%22small%22%2C%2215_5617_5%22%2C%2214_11360_5%22%2C%223_6627_5%22%2C%223_2908_5%22%2C%222_5452_5%22%5D%2C%5B%22size%22%2C%2218_9402_8%22%2C%226_4362_5%22%5D%2C%5B%22French%22%2C%2221_1144_8%22%2C%2222_10566_8%22%2C%2220_1454_8%22%2C%2223_2592_8%22%2C%2219_5802_8%22%5D%5D&clickedId=22_10566_8&densityThreshold=0.99)\n",
        "- Chinese: [`\"小\"的反义词是\"` → `大`](http://neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-zh&pruningThreshold=0.65&pinnedIds=27_235469_8%2CE_235585_2%2C23_8488_8%2C23_8683_8%2C21_10062_8%2C19_5058_8%2C22_11933_8%2C21_9377_8%2C18_9402_8%2C15_5617_2%2C14_11360_2%2C14_13476_2%2C2_2169_2%2C1_10169_2%2C8_1988_6%2C4_15846_6%2C4_7409_6%2CE_208659_4%2CE_237379_6%2CE_236711_5%2C24_2394_8%2C23_13630_8%2C21_13505_8%2C20_12983_8&supernodes=%5B%5B%22reverse%22%2C%224_7409_6%22%2C%228_1988_6%22%2C%224_15846_6%22%5D%2C%5B%22small%22%2C%2215_5617_2%22%2C%2214_11360_2%22%5D%2C%5B%22say+big+%2F+large%22%2C%2223_8683_8%22%2C%2221_10062_8%22%2C%2223_8488_8%22%5D%2C%5B%22Chinese%22%2C%2224_2394_8%22%2C%2222_11933_8%22%2C%2220_12983_8%22%2C%2221_13505_8%22%2C%2223_13630_8%22%5D%2C%5B%22Chinese-related+English+text%22%2C%221_10169_2%22%2C%2214_13476_2%22%5D%2C%5B%22size%22%2C%2218_9402_8%22%2C%222_2169_2%22%5D%2C%5B%22comparatives%22%2C%2221_9377_8%22%2C%2219_5058_8%22%5D%5D&clickedId=27_235469_8&densityThreshold=0.99)\n",
        "\n",
        "Work on Haiku showed one shared multilingual circuit:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/safety-research/circuit-tracer/main/demos/img/multilingual-haiku.png\" width=\"900\" />\n",
        "\n",
        "Our circuits indicate the same behavior. In fact, unlike the Haiku circuits, the Gemma 2 (2B) circuits are essentially entirely multilingual. There are no individual \"Say big\" or \"Say grand\" supernodes that cause the model to output a specific answer in a specific language. Instead, all circuits use \"Say big\" features, combined with a \"French\" or \"Chinese\" feature if the answer is non-English.\n",
        "\n",
        "Let's study these circuits by performing interventions on them. First, we'll create Supernode objects, as before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yfKFn7WwnEn"
      },
      "outputs": [],
      "source": [
        "url_fr = 'https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-fr&clerps=%5B%5D&pruningThreshold=0.65&pinnedIds=27_21996_8%2CE_64986_5%2C24_16045_8%2C19_5058_8%2C21_10062_8%2C23_2592_8%2C20_1454_8%2CE_63265_2%2C23_8683_8%2C23_8488_8%2C20_11434_8%2C19_5802_8%2CE_1455_7%2C15_5617_5%2C18_9402_8%2C6_4362_5%2C14_11360_5%2C3_2908_5%2C2_5452_5%2C3_6627_5%2C6_16184_2%2C4_95_2%2C22_10566_8%2C21_1144_8%2CE_2025_1%2CE_581_3%2C5_982_2%2C6_651_2%2C5_8646_2%2C6_2743_2%2C8_1988_2%2C4_7409_2%2C4_15846_2%2C3_11241_2%2C2_321_2%2C2_4657_2&supernodes=%5B%5B%22say+big+%2F+large%22%2C%2223_8683_8%22%2C%2223_8488_8%22%2C%2221_10062_8%22%5D%2C%5B%22too%22%2C%2219_5058_8%22%2C%2224_16045_8%22%2C%2220_11434_8%22%5D%2C%5B%22small%22%2C%2215_5617_5%22%2C%2214_11360_5%22%2C%223_6627_5%22%2C%223_2908_5%22%2C%222_5452_5%22%5D%2C%5B%22size%22%2C%2218_9402_8%22%2C%226_4362_5%22%5D%2C%5B%22French%22%2C%2221_1144_8%22%2C%2222_10566_8%22%2C%2220_1454_8%22%2C%2223_2592_8%22%2C%2219_5802_8%22%5D%2C%5B%22opposite%22%2C%226_16184_2%22%2C%224_95_2%22%2C%225_8646_2%22%2C%226_2743_2%22%2C%228_1988_2%22%2C%226_651_2%22%2C%225_982_2%22%2C%222_321_2%22%2C%223_11241_2%22%2C%222_4657_2%22%2C%224_7409_2%22%2C%224_15846_2%22%5D%5D&clickedId=3_11241_2'\n",
        "supernodes_fr, _ = decode_url_features(url_fr)\n",
        "french_node = Supernode('French', features=supernodes_fr['French'], children=[])\n",
        "say_big_node = Supernode('Say big', features=supernodes_fr[\"say big / large\"])\n",
        "small_node = Supernode('small', features=supernodes_fr['small'], children=[say_big_node])\n",
        "opposite_node = Supernode('opposite', features=supernodes_fr['opposite'], children=[say_big_node])\n",
        "\n",
        "url_en = 'https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-en&clerps=%5B%5D&pruningThreshold=0.65&pinnedIds=27_13210_8%2CE_10498_5%2C23_8683_8%2C21_10062_8%2C17_12530_5%2C18_9402_8%2C6_4362_5%2C15_5617_5%2C15_5756_5%2C19_5058_8%2C14_11360_5%2CE_13388_2%2C15_7209_2%2C4_95_2%2C3_6576_2%2C27_7773_8%2C7_10545_5&supernodes=%5B%5B%22Output+%5C%22big%5C%22+or+%5C%22large%5C%22%22%2C%2227_7773_8%22%2C%2227_13210_8%22%5D%2C%5B%22say+big+%2F+huge+%2F+large%22%2C%2221_10062_8%22%2C%2223_8683_8%22%5D%2C%5B%22opposite%22%2C%224_95_2%22%2C%2215_7209_2%22%2C%223_6576_2%22%5D%2C%5B%22small%22%2C%2214_11360_5%22%2C%2217_12530_5%22%2C%2215_5617_5%22%5D%2C%5B%22large+%2F+size%22%2C%226_4362_5%22%2C%227_10545_5%22%2C%2215_5756_5%22%5D%5D&clickedId=6_4362_5'\n",
        "supernodes_en, _ = decode_url_features(url_en)\n",
        "\n",
        "\n",
        "url_zh = 'https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-zh&clerps=%5B%5D&pruningThreshold=0.65&pinnedIds=27_235469_8%2CE_235585_2%2C23_8488_8%2C23_8683_8%2C21_10062_8%2C19_5058_8%2C22_11933_8%2C21_9377_8%2C18_9402_8%2C15_5617_2%2C14_11360_2%2C14_13476_2%2C2_2169_2%2C1_10169_2%2C8_1988_6%2C4_15846_6%2C4_7409_6%2CE_208659_4%2CE_237379_6%2CE_236711_5%2C24_2394_8%2C23_13630_8%2C21_13505_8%2C20_12983_8&supernodes=%5B%5B%22reverse%22%2C%224_7409_6%22%2C%228_1988_6%22%2C%224_15846_6%22%5D%2C%5B%22small%22%2C%2215_5617_2%22%2C%2214_11360_2%22%5D%2C%5B%22say+big+%2F+large%22%2C%2223_8683_8%22%2C%2221_10062_8%22%2C%2223_8488_8%22%5D%2C%5B%22Chinese%22%2C%2224_2394_8%22%2C%2222_11933_8%22%2C%2220_12983_8%22%2C%2221_13505_8%22%2C%2223_13630_8%22%5D%2C%5B%22Chinese-related+English+text%22%2C%221_10169_2%22%2C%2214_13476_2%22%5D%2C%5B%22size%22%2C%2218_9402_8%22%2C%222_2169_2%22%5D%5D&clickedId=27_235469_8'\n",
        "supernodes_zh, _ = decode_url_features(url_zh)\n",
        "chinese_node = Supernode('Chinese', features=supernodes_zh['Chinese'] + supernodes_zh['Chinese-related English text'], children=[])\n",
        "\n",
        "ordered_nodes_fr = [[french_node, opposite_node, small_node], [say_big_node]]\n",
        "\n",
        "prompt_en = 'The opposite of \"small\" is \"'\n",
        "prompt_fr = 'Le contraire de \"petit\" est \"'\n",
        "prompt_zh = '\"小\"的反义词是\"'\n",
        "\n",
        "small_big_graph = InterventionGraph(ordered_nodes=ordered_nodes_fr, prompt=prompt_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHqiM2SRwnEn"
      },
      "source": [
        "Then, we get the activations for these nodes, initialize them, and create a visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ9YWogSwnEn"
      },
      "outputs": [],
      "source": [
        "logits_fr, activations_fr = model.get_activations(prompt_fr)\n",
        "\n",
        "for node in [say_big_node, small_node, french_node, opposite_node]:\n",
        "    small_big_graph.initialize_node(node, activations_fr)  # initialize each node, adding it to the graph and recording its default activation\n",
        "\n",
        "logits_zh, activations_zh = model.get_activations(prompt_zh)\n",
        "small_big_graph.initialize_node(chinese_node, activations_zh)\n",
        "\n",
        "small_big_graph.set_node_activation_fractions(activations_fr)  # set each node's current activation to a percent of its default activation (here always 100%)\n",
        "create_graph_visualization(small_big_graph, get_top_outputs(logits_fr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgA0HnsKwnEn"
      },
      "source": [
        "Great! Now let's perform our first intervention: we'll turn off the French supernode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-06P8ffwnEo"
      },
      "outputs": [],
      "source": [
        "french_to_english_interventions = [Intervention(french_node, -2)]\n",
        "supernode_intervention(small_big_graph, french_to_english_interventions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7SpdtFdwnEo"
      },
      "source": [
        "Turning off the French supernode resulted in English output! Notably, it had only minor effects on the \"Say big\" supernode; their effects seem to be independent.\n",
        "\n",
        "Now, let's try to change the language to another: we'll turn off the French supernode, and turn on the Chinese supernode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S-RMB98wnEo"
      },
      "outputs": [],
      "source": [
        "french_to_chinese_interventions = [Intervention(french_node, -2), Intervention(chinese_node, 2)]\n",
        "supernode_intervention(small_big_graph, french_to_chinese_interventions, replacements={french_node.name: chinese_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggB1P_7jwnEr"
      },
      "source": [
        "As expected, the model's output post-intervention is identical to its original output on the Chinese example.\n",
        "\n",
        "What if we replace the \"small\" feature with a \"big\" feature?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOdRVPvVwnEr"
      },
      "outputs": [],
      "source": [
        "url_fr_big_small = 'https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-big-small-fr&clerps=%5B%5D&pruningThreshold=0.65&clickedId=21_9082_8&pinnedIds=27_64986_8%2CE_21996_5%2C21_9082_8%2C15_5756_5%2C6_4362_5%2C3_2873_5%2C2_4298_5&supernodes=%5B%5B%22large+%2F+huge%22%2C%2215_5756_5%22%2C%226_4362_5%22%2C%223_2873_5%22%2C%222_4298_5%22%5D%5D'\n",
        "supernodes_fr_big_small, _ = decode_url_features(url_fr_big_small)\n",
        "say_small_node = Supernode('Say small', features=[Feature(layer=21, pos=8, feature_idx=9082)])\n",
        "big_node = Supernode('big', features=supernodes_fr_big_small['large / huge'], children=[say_small_node])\n",
        "\n",
        "prompt_fr_rev = 'Le contraire de \"grand\" est \"'\n",
        "logits_fr_rev, activations_fr_rev = model.get_activations(prompt_fr_rev)\n",
        "\n",
        "for node in [say_small_node, big_node]:\n",
        "    small_big_graph.initialize_node(node, activations_fr_rev)  # initialize each node, adding it to the graph and recording its default activation\n",
        "\n",
        "big_to_small_interventions = [Intervention(small_node, -2), Intervention(big_node, 2)]\n",
        "supernode_intervention(small_big_graph, big_to_small_interventions, replacements={small_node.name: big_node, say_big_node.name: say_small_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqQkIE8TwnEr"
      },
      "source": [
        "Replacing the \"small\" supernode with a \"big\" supernode causes the \"Say big\" supernode to shut off, and a new \"Say small\" supernode to turn on! The model's output changes to \"petit\", or \"small\", in French.\n",
        "\n",
        "We'll try one last intervention - can we replace the \"opposite\" supernode with a \"synonym\" supernode, to obtain a synonymous output? Our model is not very good at synonymy; given 'Un synonyme de \"petit\" est \"', it repeats \"petit\", rather than another synonym. But we can still see if this intervention reproduces that behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjVYnMZUwnEr"
      },
      "outputs": [],
      "source": [
        "url_fr_syn = 'https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-min-fr&clerps=%5B%5D&pruningThreshold=0.8&pinnedIds=27_64986_9%2C27_69658_9%2CE_64986_6%2C8_11850_3%2CE_14904_2%2C4_13762_3%2C6_10175_3%2C3_15891_3&supernodes=%5B%5B%22synonymy%22%2C%223_15891_3%22%2C%228_11850_3%22%2C%224_13762_3%22%2C%226_10175_3%22%5D%5D&clickedId=5_13985_3'\n",
        "supernodes_fr_syn, _ = decode_url_features(url_fr_syn)\n",
        "say_small_node2 = Supernode('say small', features=[Feature(layer=21, pos=8, feature_idx=9082)])\n",
        "synonym_node = Supernode('synonym', features=supernodes_fr_syn['synonymy'], children=[say_small_node2])\n",
        "\n",
        "prompt_fr_syn = 'Un synonyme de \"petit\" est \"'\n",
        "logits_fr_syn, activations_fr_syn = model.get_activations(prompt_fr_syn)\n",
        "print('Top outputs for Un synonyme de \"petit\" est \": ', get_top_outputs(logits_fr_syn))\n",
        "\n",
        "small_big_graph.initialize_node(synonym_node, activations_fr_syn)  # initialize each node, adding it to the graph and recording its default activation\n",
        "synonym_node.features = [Feature(layer=f.layer, pos=f.pos-1, feature_idx=f.feature_idx) for f in synonym_node.features]\n",
        "\n",
        "antonym_to_synonym_interventions = [Intervention(opposite_node, -2), Intervention(synonym_node, 2)]\n",
        "supernode_intervention(small_big_graph, antonym_to_synonym_interventions, replacements={opposite_node.name: synonym_node, say_big_node.name: say_small_node})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbNuCtqFwnEr"
      },
      "source": [
        "Unfortunately, this intervention doesn't work! Though the \"Say small\" supernode turns on, the \"Say big\" supernode stays on too, and the model's outputs don't change. This is not very surprising - if we look at the original [circuit](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-small-big-fr&clerps=%5B%5D&pruningThreshold=0.65&pinnedIds=27_21996_8%2CE_64986_5%2C24_16045_8%2C19_5058_8%2C21_10062_8%2C23_2592_8%2C20_1454_8%2CE_63265_2%2C23_8683_8%2C23_8488_8%2C20_11434_8%2C19_5802_8%2CE_1455_7%2C15_5617_5%2C18_9402_8%2C6_4362_5%2C14_11360_5%2C3_2908_5%2C2_5452_5%2C3_6627_5%2C6_16184_2%2C4_95_2%2C22_10566_8%2C21_1144_8%2CE_2025_1%2CE_581_3&supernodes=%5B%5B%22opposite%22%2C%226_16184_2%22%2C%224_95_2%22%5D%2C%5B%22say+big+%2F+large%22%2C%2223_8683_8%22%2C%2223_8488_8%22%2C%2221_10062_8%22%5D%2C%5B%22too%22%2C%2219_5058_8%22%2C%2224_16045_8%22%2C%2220_11434_8%22%5D%2C%5B%22small%22%2C%2215_5617_5%22%2C%2214_11360_5%22%2C%223_6627_5%22%2C%223_2908_5%22%2C%222_5452_5%22%5D%2C%5B%22size%22%2C%2218_9402_8%22%2C%226_4362_5%22%5D%2C%5B%22French%22%2C%2221_1144_8%22%2C%2222_10566_8%22%2C%2220_1454_8%22%2C%2223_2592_8%22%2C%2219_5802_8%22%5D%5D&clickedId=22_10566_8) for the task, we see that the \"opposite\" supernode has only weak connections to the output. As a result, its causal effect is rather low, even though it would make sense for it to play a role."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff_rs4y2wnEr"
      },
      "source": [
        "## Other Notebooks and (Un)Labeled Circuits\n",
        "\n",
        "Want to learn more? Check out the following other notebooks in the `demos` folder:\n",
        "These how to use our library:\n",
        "- `demos/attribute_demo.ipynb`: Demonstrates how to find circuits and visualize them.\n",
        "- `demos/intervention_demo.ipynb`: Demonstrates how to perform interventions on models.\n",
        "\n",
        "These dig deeper into specific, pre-computed and pre-annotated attribution graphs, performing interventions to demonstrate the correctness of the annotated graph:\n",
        "- `demos/gemma_demo.ipynb`: Explores graphs from Gemma 2 (2B)\n",
        "- `demos/gemma_it_demo.ipynb`: Explores graphs from instruction-tuned Gemma 2 (2B), using transcoders from the base model.\n",
        "- `demos/llama_demo.ipynb`: Explores graphs from Llama 3.2 (1B)\n",
        "\n",
        "You can also explore some more labeled examples:\n",
        "- [`The girls that the teacher sees` → `are`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-girls-are&pinnedIds=27_708_6%2C25_9974_6%2C22_11517_6%2CE_8216_2%2CE_674_3%2CE_651_1%2C19_1880_6%2C15_13979_6%2C17_7377_6%2C18_703_6%2C16_3689_6%2C15_4906_6%2C15_233_6%2CE_17733_6%2C3_6616_6%2C6_11265_6%2C5_1034_6%2C4_2671_6%2C3_6243_4%2C3_9864_3%2C0_13503_3&clickedId=3_9864_3&supernodes=%5B%5B%22see%2Fsaw%22%2C%2215_233_6%22%2C%226_11265_6%22%2C%223_6616_6%22%5D%2C%5B%22ends+of+noun+phrases+%28predict+a+verb%29%22%2C%2219_1880_6%22%2C%2217_7377_6%22%5D%2C%5B%22verbs+ending+relative+clauses%22%2C%224_2671_6%22%2C%2215_4906_6%22%2C%2215_13979_6%22%2C%2218_703_6%22%5D%2C%5B%22that%22%2C%220_13503_3%22%2C%223_9864_3%22%5D%5D&pruningThreshold=0.7&densityThreshold=0.99&clerps=%5B%5B%2225_2509974_6%22%2C%22say+are%22%5D%2C%5B%225_501034_6%22%2C%22transitive+verbs+with+objects+preceding+htem%22%5D%5D)\n",
        "- [`The International Advanced Security Group (IAS` → `G`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-G&pinnedIds=25_5604_7%2C24_763_7%2C22_12304_7%2C23_14585_7%2C24_1668_7%2C20_7544_7%2C17_4855_5%2C24_9503_7%2C17_4886_5%2C14_1031_5%2C13_7451_5%2C4_3134_5%2CE_5897_5%2C1_3977_5%2C13_5661_7%2C11_10532_7%2C11_7419_7%2C10_4451_7%2C6_9719_7%2CE_24632_7%2CE_591_6%2C0_548_7%2C2_12787_7%2C2_12811_7%2C2_4716_7%2C2_8870_7%2C5_10381_7%2C6_3358_7%2C7_7303_7%2C7_4807_7%2C7_15088_7%2C8_4119_7%2C10_2379_7%2C9_15938_7%2C10_8308_7%2C10_11210_7%2C14_922_7%2C15_5076_7%2C14_15510_7%2C15_444_7%2C17_14853_7%2C27_235319_7%2C2_8493_5%2C3_4791_6%2C4_6672_6%2C5_12154_6%2C5_112_6%2C8_15626_7%2C13_945_6%2C9_13890_6%2C5_12910_7%2C14_1031_6%2C14_13599_6%2C21_5066_6%2C13_13476_6%2C16_3033_6%2C25_4062_7%2C15_1301_6%2C6_11788_7%2C7_12830_7%2C11_8369_6%2C0_14394_7%2C0_7197_7%2C0_4370_7%2C0_3410_7%2C0_5548_7%2C0_13190_7%2C0_2592_7%2C1_10188_7%2C15_12642_5%2C23_999_7%2C14_13969_5%2C21_1146_7%2C24_2871_7%2C25_5880_7%2C24_7620_7%2C23_12120_7%2C25_10087_7&supernodes=%5B%5B%22Activates+on+%28+before+acronym+%2F+upweights+G*%22%2C%2220_7544_7%22%2C%2222_12304_7%22%5D%2C%5B%22%5C%22group%5C%22%22%2C%221_3977_5%22%2C%222_8493_5%22%2C%2217_4855_5%22%5D%2C%5B%22Activates+on+%28+before+acronym%22%2C%2221_5066_6%22%2C%2211_8369_6%22%2C%2213_945_6%22%2C%229_13890_6%22%2C%2214_13599_6%22%2C%2215_1301_6%22%2C%2216_3033_6%22%2C%2213_13476_6%22%2C%225_112_6%22%2C%225_12154_6%22%2C%224_6672_6%22%2C%223_4791_6%22%5D%2C%5B%22Predict+tokens+starting+with+G%22%2C%2223_999_7%22%2C%2224_1668_7%22%2C%2225_5604_7%22%5D%2C%5B%22Tokens+in+acronymable+proper+nouns%22%2C%2213_7451_5%22%2C%2214_13969_5%22%5D%2C%5B%22tokens+followed+by+G%22%2C%2221_1146_7%22%2C%2224_2871_7%22%2C%2225_5880_7%22%2C%2224_7620_7%22%5D%2C%5B%22all+caps%22%2C%2225_10087_7%22%2C%2223_12120_7%22%2C%2223_14585_7%22%2C%2224_763_7%22%5D%2C%5B%22Tokens+starting+with+G%22%2C%2214_1031_6%22%2C%2215_12642_5%22%2C%2214_1031_5%22%2C%224_3134_5%22%2C%2217_4886_5%22%5D%2C%5B%22first+token+of+acronyms%22%2C%220_7197_7%22%2C%220_5548_7%22%2C%220_3410_7%22%2C%220_4370_7%22%2C%222_8870_7%22%2C%220_13190_7%22%2C%220_14394_7%22%2C%220_2592_7%22%2C%221_10188_7%22%2C%227_12830_7%22%2C%2213_5661_7%22%2C%2214_922_7%22%2C%2217_14853_7%22%2C%227_15088_7%22%2C%229_15938_7%22%2C%2210_8308_7%22%2C%2215_5076_7%22%2C%2210_11210_7%22%2C%2211_10532_7%22%2C%226_9719_7%22%2C%225_10381_7%22%2C%222_12811_7%22%2C%222_4716_7%22%5D%2C%5B%22tokens+of+acronyms+in+parentheses%22%2C%2215_444_7%22%2C%228_4119_7%22%2C%2210_2379_7%22%2C%226_3358_7%22%2C%225_12910_7%22%2C%2224_9503_7%22%2C%226_11788_7%22%2C%2225_4062_7%22%2C%220_548_7%22%2C%2211_7419_7%22%2C%2210_4451_7%22%2C%2214_15510_7%22%2C%227_7303_7%22%2C%227_4807_7%22%2C%222_12787_7%22%2C%228_15626_7%22%5D%5D&clickedId=24_13541_7&pruningThreshold=0.7&densityThreshold=0.99)\n",
        "- [`The guitarist knew the song` → `. / is`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-gp-nps&clerps=%5B%5B%222413277%22%2C%22%28incomprehensible%29%22%5D%2C%5B%222106697%22%2C%22The+X+at+start+of+sentence+%28subject+NPs%29%22%5D%2C%5B%222012754%22%2C%22ends+of+NPs%2C+upweights+verbs%22%5D%2C%5B%222305096%22%2C%22ends+of+phrases+%22%5D%2C%5B%222001993%22%2C%22say+%5C%22would%5C%22%22%5D%2C%5B%222111913%22%2C%22subject+in+sentential+clause+%28say+%5C%22had%5C%22%29%22%5D%2C%5B%222012650%22%2C%22say+a+verb%22%5D%2C%5B%221702296%22%2C%22thought+%28say+a+verb%29%22%5D%2C%5B%221609179%22%2C%22knew%22%5D%2C%5B%221401162%22%2C%22was%2Fwere%22%5D%2C%5B%221303459%22%2C%22knew%2Fknow%22%5D%2C%5B%222310652%22%2C%22subject+in+sentential+clause+%28say+%5C%22would%5C%22%29%22%5D%2C%5B%222514276%22%2C%22don%27t+say+%5C%22well%5C%22%22%5D%2C%5B%222206853%22%2C%22don%27t+say+%5C%22well%5C%22%22%5D%2C%5B%221915834%22%2C%22say+%5C%22well%5C%22%22%5D%2C%5B%221409346%22%2C%22know%22%5D%2C%5B%222301993%22%2C%22say+%5C%22was%5C%22%22%5D%2C%5B%222207306%22%2C%22say+%5C%22was%5C%22%22%5D%2C%5B%222108443%22%2C%22say+%5C%22well%5C%22%22%5D%2C%5B%22701641%22%2C%22know+%2F+understand%22%5D%2C%5B%22600576%22%2C%22know+%28that%29%22%5D%2C%5B%221804181%22%2C%22sentential+verbs+%28say+a+verb%29%22%5D%2C%5B%22205370%22%2C%22want%22%5D%2C%5B%22307146%22%2C%22know%22%5D%2C%5B%22414214%22%2C%22know%22%5D%2C%5B%222105739%22%2C%22ends+of+phrases%22%5D%2C%5B%221914505%22%2C%22%5C%22song%5C%22%22%5D%2C%5B%221500908%22%2C%22know%22%5D%2C%5B%22600908%22%2C%22know%22%5D%2C%5B%222301612%22%2C%22say+a+verb%22%5D%2C%5B%222101806%22%2C%22say+a+verb%22%5D%2C%5B%221204795%22%2C%22know%22%5D%2C%5B%2221_2111913_5%22%2C%22sentential+subjects+%28say+a+verb%29%22%5D%5D&pinnedIds=27_729_5%2CE_6608_3%2C21_11913_5%2C23_1993_5%2C20_12650_5%2C22_7306_5%2CE_91939_2%2CE_5169_5%2C17_2296_3%2C18_4181_5%2C14_9346_3%2C20_1993_5%2C19_14505_5%2C16_9179_3%2C15_908_3%2C14_9346_4%2C6_576_3%2C6_908_3%2C12_4795_3%2C13_3459_3%2C7_1641_3%2C4_14214_3%2C23_1612_5%2C21_1806_5&supernodes=%5B%5B%22say+a+verb%22%2C%2220_12650_5%22%2C%2221_1806_5%22%2C%2223_1612_5%22%5D%2C%5B%22say+%5C%22was%5C%22%22%2C%2223_1993_5%22%2C%2222_7306_5%22%5D%2C%5B%22knew%22%2C%2216_9179_3%22%2C%224_14214_3%22%2C%2213_3459_3%22%2C%2212_4795_3%22%2C%2214_9346_3%22%2C%2215_908_3%22%2C%227_1641_3%22%2C%226_576_3%22%2C%226_908_3%22%2C%2214_9346_4%22%5D%2C%5B%22ends+of+phrases%22%2C%2221_5739_5%22%2C%2223_5096_5%22%5D%2C%5B%22ends+of+NPs%2C+upweights+verbs%22%2C%2220_12754_5%22%2C%2221_6697_5%22%5D%2C%5B%22sentential+verbs+%28say+a+verb%29%22%2C%2221_11913_5%22%2C%2218_4181_5%22%2C%2217_2296_3%22%5D%5D&pruningThreshold=0.51&densityThreshold=0.99)\n",
        "\n",
        "Or try to find circuits in unlabeled ones!:\n",
        "- [`The language most commonly spoken in the country south of the United States is` → `Spanish`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-Mexico-Spanish&clickedId=undefined&pruningThreshold=0.7&densityThreshold=0.99)\n",
        "- [`A bee is a type of` → `insect`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-bee-insect&clerps=%5B%5D&clickedId=undefined)\n",
        "- [`cat, bat, hat` → `rat`](https://www.neuronpedia.org/gemma-2-2b/graph?slug=gemma-cat-hat&clerps=%5B%5D&clickedId=undefined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuT4f5nqwnEr"
      },
      "source": [
        "<head>\n",
        "    <style>\n",
        "        body {\n",
        "            margin: 20px;\n",
        "            font-family: Arial, sans-serif;\n",
        "            background-color: #f5f5f5;\n",
        "        }\n",
        "        \n",
        "        .container {\n",
        "            background: white;\n",
        "            border-radius: 12px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
        "            max-width: 900px;\n",
        "            margin: 0 auto;\n",
        "        }\n",
        "        \n",
        "        .title {\n",
        "            font-size: 18px;\n",
        "            font-weight: bold;\n",
        "            color: #666;\n",
        "            margin-bottom: 20px;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 1px;\n",
        "        }\n",
        "        \n",
        "        .graph-container {\n",
        "            position: relative;\n",
        "            height: 400px;\n",
        "            margin: 20px 0;\n",
        "            overflow: visible;\n",
        "        }\n",
        "        \n",
        "        .node {\n",
        "            position: absolute;\n",
        "            background: #e8e8e8;\n",
        "            border: 2px solid #999;\n",
        "            border-radius: 8px;\n",
        "            padding: 12px 16px;\n",
        "            font-weight: bold;\n",
        "            color: #333;\n",
        "            text-align: center;\n",
        "            cursor: pointer;\n",
        "            transition: all 0.3s ease;\n",
        "            min-width: 80px;\n",
        "            box-sizing: border-box;\n",
        "        }\n",
        "        \n",
        "        .node.low-activation {\n",
        "            background: #f0f0f0;\n",
        "            color: #bbb;\n",
        "            border-color: #ddd;\n",
        "        }\n",
        "        \n",
        "        .node.replacement {\n",
        "            border: 2px solid #D2691E;\n",
        "            background: #FFF8DC;\n",
        "        }\n",
        "        \n",
        "        .node:hover {\n",
        "            transform: translateY(-2px);\n",
        "            box-shadow: 0 4px 12px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        \n",
        "        .activation-label {\n",
        "            position: absolute;\n",
        "            font-size: 12px;\n",
        "            font-weight: bold;\n",
        "            color: #8B4513;\n",
        "            background: white;\n",
        "            padding: 2px 6px;\n",
        "            border-radius: 4px;\n",
        "            border: 1px solid #ccc;\n",
        "            white-space: nowrap;\n",
        "        }\n",
        "        \n",
        "        .intervention {\n",
        "            position: absolute;\n",
        "            background: #D2691E;\n",
        "            color: white;\n",
        "            border-radius: 12px;\n",
        "            padding: 4px 12px;\n",
        "            font-size: 12px;\n",
        "            font-weight: bold;\n",
        "            white-space: nowrap;\n",
        "        }\n",
        "        \n",
        "        .connection {\n",
        "            position: absolute;\n",
        "            background: #8B4513;\n",
        "            height: 3px;\n",
        "            transform-origin: left center;\n",
        "        }\n",
        "        \n",
        "        .connection.replacement {\n",
        "            background: #D2691E;\n",
        "            height: 4px;\n",
        "        }\n",
        "        \n",
        "        .arrow {\n",
        "            position: absolute;\n",
        "            width: 0;\n",
        "            height: 0;\n",
        "            border-left: 8px solid #8B4513;\n",
        "            border-top: 5px solid transparent;\n",
        "            border-bottom: 5px solid transparent;\n",
        "        }\n",
        "        \n",
        "        .arrow.replacement {\n",
        "            border-left-color: #D2691E;\n",
        "        }\n",
        "        \n",
        "        .prompt-section {\n",
        "            margin-top: 30px;\n",
        "            padding-top: 20px;\n",
        "            border-top: 1px solid #ddd;\n",
        "        }\n",
        "        \n",
        "        .prompt-title {\n",
        "            font-size: 16px;\n",
        "            font-weight: bold;\n",
        "            color: #666;\n",
        "            margin-bottom: 10px;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 0.5px;\n",
        "        }\n",
        "        \n",
        "        .prompt-text {\n",
        "            font-size: 16px;\n",
        "            line-height: 1.5;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        \n",
        "        .outputs-section {\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        \n",
        "        .outputs-title {\n",
        "            font-size: 14px;\n",
        "            font-weight: bold;\n",
        "            color: #666;\n",
        "            margin-bottom: 15px;\n",
        "            text-transform: uppercase;\n",
        "            letter-spacing: 0.5px;\n",
        "        }\n",
        "        \n",
        "        .output-items {\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 10px;\n",
        "        }\n",
        "        \n",
        "        .output-item {\n",
        "            background: #e8e8e8;\n",
        "            padding: 6px 12px;\n",
        "            border-radius: 6px;\n",
        "            font-weight: bold;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            gap: 8px;\n",
        "        }\n",
        "        \n",
        "        .output-percentage {\n",
        "            font-size: 12px;\n",
        "            color: #666;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <div class=\"title\">Graph & Interventions</div>\n",
        "        \n",
        "        <div class=\"graph-container\" id=\"graphContainer\">\n",
        "            <!-- Supernodes and connections will be positioned here -->\n",
        "        </div>\n",
        "        \n",
        "        <div class=\"prompt-section\">\n",
        "            <div class=\"prompt-title\">Prompt</div>\n",
        "            <div class=\"prompt-text\" id=\"promptText\">\n",
        "                <!-- Prompt will be inserted here -->\n",
        "            </div>\n",
        "            \n",
        "            <div class=\"outputs-section\">\n",
        "                <div class=\"outputs-title\">Top Outputs</div>\n",
        "                <div class=\"output-items\" id=\"outputItems\">\n",
        "                    <!-- Output items will be inserted here -->\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        // Configuration - can be modified\n",
        "        const prompt = \"Fact: the capital of the state containing Dallas is\";\n",
        "        const top_outputs = [[\"Sacramento\", 0.97], [\"\", 0.007], [\"not\", 0.004], [\"the\", 0.003], [\"⏎\", 0.003], [\"()\", 0.002]];\n",
        "        \n",
        "        // Supernode layout configuration (base nodes only - replacements will be positioned automatically)\n",
        "        const nodes = [\n",
        "            ['capital', 'state', 'Dallas'],\n",
        "            ['Say a capital', 'Texas'],\n",
        "            ['Say Austin']\n",
        "        ];\n",
        "        \n",
        "        // Supernode properties (without x,y coordinates)\n",
        "        const nodeProperties = {\n",
        "            'capital': { activation: 1.0 },\n",
        "            'state': { activation: 1.0 },\n",
        "            'Dallas': { activation: 1.0 },\n",
        "            'Say a capital': { activation: 0.91 },\n",
        "            'Texas': { activation: null, intervention: '-2x', replacement_node: 'California' },\n",
        "            'Say Austin': { activation: 0.0, replacement_node: 'Say Sacramento' },\n",
        "            'California': { activation: null, intervention: '+2x', children: ['Say Sacramento'] },\n",
        "            'Say Sacramento': { activation: null }\n",
        "        };\n",
        "\n",
        "        // Connection data - includes both original and replacement connections\n",
        "        const connections = [\n",
        "            { from: 'capital', to: 'Say a capital' },\n",
        "            { from: 'state', to: 'Say a capital' },\n",
        "            { from: 'state', to: 'Texas' },\n",
        "            { from: 'Dallas', to: 'Texas' },\n",
        "            { from: 'Say a capital', to: 'Say Austin' },\n",
        "            { from: 'Texas', to: 'Say Austin', replacement: true }, // This gets replaced\n",
        "            { from: 'California', to: 'Say Sacramento', replacement: true }\n",
        "        ];\n",
        "\n",
        "        // Auto-calculate positions based on node layout\n",
        "        function calculateSupernodePositions() {\n",
        "            const containerWidth = 800;\n",
        "            const containerHeight = 350;\n",
        "            const nodeWidth = 120;\n",
        "            const nodeHeight = 40;\n",
        "            \n",
        "            const nodeData = {};\n",
        "            \n",
        "            // First, position the base nodes from the layout\n",
        "            for (let rowIndex = 0; rowIndex < nodes.length; rowIndex++) {\n",
        "                const row = nodes[rowIndex];\n",
        "                const rowY = containerHeight - (rowIndex * (containerHeight / (nodes.length + 0.5)));\n",
        "                \n",
        "                for (let colIndex = 0; colIndex < row.length; colIndex++) {\n",
        "                    const nodeName = row[colIndex];\n",
        "                    const rowWidth = row.length * nodeWidth + (row.length - 1) * 50;\n",
        "                    const startX = (containerWidth - rowWidth) / 2;\n",
        "                    const nodeX = startX + colIndex * (nodeWidth + 50);\n",
        "                    \n",
        "                    nodeData[nodeName] = {\n",
        "                        x: nodeX,\n",
        "                        y: rowY,\n",
        "                        ...nodeProperties[nodeName]\n",
        "                    };\n",
        "                }\n",
        "            }\n",
        "            \n",
        "            // Then, position replacement nodes directly above their original nodes (with slight offset)\n",
        "            Object.keys(nodeProperties).forEach(nodeName => {\n",
        "                const nodeProps = nodeProperties[nodeName];\n",
        "                if (nodeProps.replacement_node && !nodeData[nodeProps.replacement_node]) {\n",
        "                    const originalSupernode = nodeData[nodeName];\n",
        "                    if (originalSupernode) {\n",
        "                        // Position replacement node directly above with small right offset, touching the original\n",
        "                        nodeData[nodeProps.replacement_node] = {\n",
        "                            x: originalSupernode.x + 30,\n",
        "                            y: originalSupernode.y - 35,\n",
        "                            ...nodeProperties[nodeProps.replacement_node]\n",
        "                        };\n",
        "                    }\n",
        "                }\n",
        "            });\n",
        "            \n",
        "            return nodeData;\n",
        "        }\n",
        "        \n",
        "        // Calculate positions\n",
        "        const nodeData = calculateSupernodePositions();\n",
        "\n",
        "        function getSupernodeCenter(nodeName) {\n",
        "            const node = nodeData[nodeName];\n",
        "            if (!node) return { x: 0, y: 0 };\n",
        "            return {\n",
        "                x: node.x + 60, // Approximate center of node\n",
        "                y: node.y + 20\n",
        "            };\n",
        "        }\n",
        "\n",
        "        function createConnections() {\n",
        "            const container = document.getElementById('graphContainer');\n",
        "            \n",
        "            connections.forEach(conn => {\n",
        "                // Skip connections where the 'from' node has a replacement and this isn't a replacement connection\n",
        "                const fromSupernodeProps = nodeProperties[conn.from];\n",
        "                if (fromSupernodeProps && fromSupernodeProps.replacement_node && !conn.replacement) {\n",
        "                    return; // Skip this connection as it's replaced\n",
        "                }\n",
        "                \n",
        "                const fromCenter = getSupernodeCenter(conn.from);\n",
        "                const toCenter = getSupernodeCenter(conn.to);\n",
        "                \n",
        "                if (fromCenter.x === 0 || toCenter.x === 0) return; // Skip if node doesn't exist\n",
        "                \n",
        "                const dx = toCenter.x - fromCenter.x;\n",
        "                const dy = toCenter.y - fromCenter.y;\n",
        "                const length = Math.sqrt(dx * dx + dy * dy);\n",
        "                const angle = Math.atan2(dy, dx) * 180 / Math.PI;\n",
        "                \n",
        "                // Create connection line\n",
        "                const line = document.createElement('div');\n",
        "                line.className = conn.replacement ? 'connection replacement' : 'connection';\n",
        "                line.style.left = fromCenter.x + 'px';\n",
        "                line.style.top = fromCenter.y + 'px';\n",
        "                line.style.width = length + 'px';\n",
        "                line.style.transform = `rotate(${angle}deg)`;\n",
        "                container.appendChild(line);\n",
        "                \n",
        "                // Create arrow at the end of the line\n",
        "                const arrowX = toCenter.x - 8;\n",
        "                const arrowY = toCenter.y - 5;\n",
        "                \n",
        "                const arrow = document.createElement('div');\n",
        "                arrow.className = conn.replacement ? 'arrow replacement' : 'arrow';\n",
        "                arrow.style.left = arrowX + 'px';\n",
        "                arrow.style.top = arrowY + 'px';\n",
        "                container.appendChild(arrow);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        function createSupernodes() {\n",
        "            const container = document.getElementById('graphContainer');\n",
        "\n",
        "            // Create nodes\n",
        "            Object.entries(nodeData).forEach(([name, data]) => {\n",
        "                const node = document.createElement('div');\n",
        "                node.className = 'node';\n",
        "                \n",
        "                // Check if node should be grayed out (low activation or negative intervention)\n",
        "                const isLowActivation = data.activation !== null && data.activation <= 0.25;\n",
        "                const hasNegativeIntervention = data.intervention && data.intervention.includes('-');\n",
        "                \n",
        "                if (isLowActivation || hasNegativeIntervention) {\n",
        "                    node.classList.add('low-activation');\n",
        "                }\n",
        "                \n",
        "                // Check if this is a replacement node\n",
        "                const isReplacement = Object.values(nodeProperties).some(props =>\n",
        "                    props.replacement_node === name\n",
        "                );\n",
        "                if (isReplacement) {\n",
        "                    node.classList.add('replacement');\n",
        "                }\n",
        "                \n",
        "                node.textContent = name;\n",
        "                node.style.left = data.x + 'px';\n",
        "                node.style.top = data.y + 'px';\n",
        "                container.appendChild(node);\n",
        "\n",
        "                // Add activation label if exists (top-left of node)\n",
        "                if (data.activation !== null) {\n",
        "                    const label = document.createElement('div');\n",
        "                    label.className = 'activation-label';\n",
        "                    label.textContent = Math.round(data.activation * 100) + '%';\n",
        "                    \n",
        "                    label.style.left = (data.x - 15) + 'px';\n",
        "                    label.style.top = (data.y - 10) + 'px';\n",
        "                    container.appendChild(label);\n",
        "                }\n",
        "\n",
        "                // Add intervention on top-left of node if exists\n",
        "                if (data.intervention) {\n",
        "                    const intervention = document.createElement('div');\n",
        "                    intervention.className = 'intervention';\n",
        "                    intervention.textContent = data.intervention;\n",
        "                    intervention.style.left = (data.x - 20) + 'px';\n",
        "                    intervention.style.top = (data.y - 10) + 'px';\n",
        "                    container.appendChild(intervention);\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        function createPromptSection() {\n",
        "            // Set prompt text\n",
        "            document.getElementById('promptText').innerHTML = `<strong>Fact:</strong> ${prompt.replace('Fact: ', '')}`;\n",
        "            \n",
        "            // Create output items\n",
        "            const outputContainer = document.getElementById('outputItems');\n",
        "            top_outputs.forEach(([text, percentage]) => {\n",
        "                const item = document.createElement('div');\n",
        "                item.className = 'output-item';\n",
        "                \n",
        "                if (text === '') {\n",
        "                    item.innerHTML = `<span class=\"output-percentage\">${Math.round(percentage * 100)}%</span>`;\n",
        "                } else {\n",
        "                    item.innerHTML = `${text} <span class=\"output-percentage\">${Math.round(percentage * 100)}%</span>`;\n",
        "                }\n",
        "                \n",
        "                outputContainer.appendChild(item);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Initialize the graph\n",
        "        createConnections();\n",
        "        createSupernodes();\n",
        "        createPromptSection();\n",
        "    </script>\n",
        "</body>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbc548ab8d6244d0ac2aa3efa1a5c7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bdd7d94c97a43059b002c08b14c2d48",
              "IPY_MODEL_6f7a27be5e4b49008ed7264b84a3d7c9",
              "IPY_MODEL_4b25a544382e417697280244428f6cb8",
              "IPY_MODEL_ed422e65078e4e14a84796b6b68fe186",
              "IPY_MODEL_1cd509497bac48d4b902f2cb40f88d86"
            ],
            "layout": "IPY_MODEL_7b900d11e03b46ca9eb0a629880a3d33",
            "tabbable": null,
            "tooltip": null
          }
        },
        "1bdd7d94c97a43059b002c08b14c2d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bb4c9b6ebc004f33a42e3951e18aa776",
            "placeholder": "​",
            "style": "IPY_MODEL_7032326d764c4c839df6d6cb29350ffd",
            "tabbable": null,
            "tooltip": null,
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "6f7a27be5e4b49008ed7264b84a3d7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_allow_html": false,
            "disabled": false,
            "layout": "IPY_MODEL_c8ad32ab93ad40a0a1688c71e1310493",
            "placeholder": "​",
            "style": "IPY_MODEL_d2bbde3f880147b4ae44fb01bb9accf6",
            "tabbable": null,
            "tooltip": null,
            "value": ""
          }
        },
        "4b25a544382e417697280244428f6cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_allow_html": false,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_91307a3ffe1548cd851c74c72a5a4361",
            "style": "IPY_MODEL_a22b25b7cd85443d9bb910a8007edab9",
            "tabbable": null,
            "tooltip": null,
            "value": true
          }
        },
        "ed422e65078e4e14a84796b6b68fe186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_cd7a80e9316141828f54c214c30b7f22",
            "style": "IPY_MODEL_f6a7580a95614e84a920dff0cd5880a5",
            "tabbable": null,
            "tooltip": null
          }
        },
        "1cd509497bac48d4b902f2cb40f88d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6eae30c213244d12965934f553ae9216",
            "placeholder": "​",
            "style": "IPY_MODEL_636e1999c22f4c57be7b0ec6a92dbaf6",
            "tabbable": null,
            "tooltip": null,
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7b900d11e03b46ca9eb0a629880a3d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "bb4c9b6ebc004f33a42e3951e18aa776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7032326d764c4c839df6d6cb29350ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c8ad32ab93ad40a0a1688c71e1310493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2bbde3f880147b4ae44fb01bb9accf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "TextStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "91307a3ffe1548cd851c74c72a5a4361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22b25b7cd85443d9bb910a8007edab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "CheckboxStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": ""
          }
        },
        "cd7a80e9316141828f54c214c30b7f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a7580a95614e84a920dff0cd5880a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_family": null,
            "font_size": null,
            "font_style": null,
            "font_variant": null,
            "font_weight": null,
            "text_color": null,
            "text_decoration": null
          }
        },
        "6eae30c213244d12965934f553ae9216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636e1999c22f4c57be7b0ec6a92dbaf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "82cb43ff71214661b3169c11e59873c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0f4a35354694d7ca6cbc9ea6ba5a81d",
              "IPY_MODEL_65e0c491ea9d46f9aa94815347ab3c8b",
              "IPY_MODEL_f057b54a37da4248a0cecf3f84478a23"
            ],
            "layout": "IPY_MODEL_214248cba974429cbcb182cc7835040f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "c0f4a35354694d7ca6cbc9ea6ba5a81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_ce812c45f7474e4e8d083e2cc0f1c16b",
            "placeholder": "​",
            "style": "IPY_MODEL_7ade0969029a44ea9fd1b737c170e3fe",
            "tabbable": null,
            "tooltip": null,
            "value": "Fetching 26 files: 100%"
          }
        },
        "65e0c491ea9d46f9aa94815347ab3c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_b20e96bce00e4a8281a5319db5b4ee5b",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1efab0384559440a9c60d2e09ee10ea3",
            "tabbable": null,
            "tooltip": null,
            "value": 26
          }
        },
        "f057b54a37da4248a0cecf3f84478a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_5e212e5f2e76473d9370391b432ed645",
            "placeholder": "​",
            "style": "IPY_MODEL_7b33b45ccaf84bd8af9403b9659913c7",
            "tabbable": null,
            "tooltip": null,
            "value": " 26/26 [00:00&lt;00:00, 97.21it/s]"
          }
        },
        "214248cba974429cbcb182cc7835040f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce812c45f7474e4e8d083e2cc0f1c16b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ade0969029a44ea9fd1b737c170e3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "b20e96bce00e4a8281a5319db5b4ee5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1efab0384559440a9c60d2e09ee10ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e212e5f2e76473d9370391b432ed645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b33b45ccaf84bd8af9403b9659913c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}